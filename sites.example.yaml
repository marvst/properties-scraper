# Procrawl Site Configuration Example (New Flat Structure)
# This is an example of a single site configuration file.
# Copy this file to sites/your_site_name.yaml and customize for your needs.
#
# Directory Structure:
#   sites/
#     ├── your_site_name.yaml    # Individual site config
#     ├── another_site.yaml      # Another site config
#     └── ...
#
# Usage:
#   python main.py --list                        # List available sites
#   python main.py <site_name>                   # Crawl a specific site
#   python main.py <site_name> --config custom_sites_dir  # Use custom sites directory

# =============================================================================
# EXAMPLE 1: URL-based Pagination (like galvao)
# =============================================================================
name: "example_url_pagination"
enabled: false
url: "https://www.example.com/listings"
base_url: "https://www.example.com"

browser:
  browser_type: "chromium"    # chromium | firefox | webkit
  headless: true              # Run browser in headless mode
  verbose: true               # Enable verbose logging

listing_scraping:
  # Setup configuration - runs before extraction
  setup:
    wait_for:
      css: ".listing-card"    # Wait for this CSS selector to appear
      # Alternatives:
      # js: "() => document.querySelectorAll('.card').length > 0"
      # time: 5000  # Wait 5 seconds
    page_timeout: 60000       # Max time to wait for page load (ms)
    cache_mode: "bypass"      # enabled | disabled | bypass | read_only | write_only

    # Pre-extraction interactions (optional) - run before any extraction
    # Useful for cookie banners, modals, etc.
    interactions:
      - type: "click"
        selector: ".cookie-accept-button"
        wait_after_ms: 1000
      - type: "js"
        code: "document.querySelector('.modal-close')?.click()"
        wait_after_ms: 500

  # URL-based pagination
  pagination:
    type: "url"               # url | js | none
    start_page: 1
    max_pages: null           # null = scrape all pages until no results
    page_template: "?page={page}"  # Appended to base URL for page > 1

  # Extraction configuration (flat structure)
  extraction:
    type: "css"               # css | llm
    base_selector: ".listing-card"
    fields:
      - name: "title"
        selector: "h2.title"
        type: "text"

      - name: "price_text"
        selector: ".price"
        type: "text"

      - name: "property_url"
        selector: "a.detail-link"
        type: "attribute"
        attribute: "href"

      - name: "image_urls"
        selector: "img.gallery"
        type: "attribute"
        attribute: "src"
        multiple: true        # Returns an array of values

  # Output configuration
  output:
    required_fields:
      - "property_url"
      - "rent_price_brl"
    unique_key:
      - "full_address"
      - "rent_price_brl"
    files:
      csv: "example_results.csv"
      json_file: "example_extracted.json"
    transform: []             # Custom transform rules (advanced)

# Details scraping (optional) - scrape individual property pages
details_scraping:
  enabled: false
  setup:
    wait_for:
      css: ".property-details"
    page_timeout: 60000
    cache_mode: "bypass"
    concurrency:
      max_requests: 2         # Max concurrent requests
      delay_ms: 2000          # Delay between requests
      timeout_per_page: 30000
    interactions: []

  extraction:
    type: "llm"
    provider: "openrouter/openai/gpt-4o-mini"
    api_token_env: "LLM_API_KEY"
    input_format: "markdown"  # markdown | html | fit_markdown
    # images field specifies which images to pass to the LLM for vision analysis
    images:
      - selector: ".main-image"
        attribute: "src"
      - selector: ".gallery img"
        attribute: "data-src"
    instruction: |
      Extract the following property information as JSON:
      {
        "full_address": "complete address",
        "condo_fee_text": "monthly fee as shown",
        "full_description": "property description"
      }
      Return only the JSON object.

---
# =============================================================================
# EXAMPLE 2: JS-based Pagination (like apolar - "load more" buttons)
# =============================================================================
# Note: Create a separate file for each site configuration

# name: "example_js_pagination"
# enabled: false
# url: "https://www.example.com/infinite-scroll-page"
#
# browser:
#   browser_type: "chromium"
#   headless: true
#   verbose: true
#
# listing_scraping:
#   setup:
#     wait_for:
#       css: ".property-card"
#     page_timeout: 120000
#     cache_mode: "bypass"
#     interactions: []
#
#   # JS-based pagination - runs JavaScript to load all content
#   pagination:
#     type: "js"
#     js_code: |
#       (async () => {
#         // Click all "load more" buttons
#         while (document.querySelector('.load-more')) {
#           document.querySelector('.load-more').click();
#           await new Promise(r => setTimeout(r, 2000));
#         }
#         window.loadingComplete = true;
#       })();
#     wait_for:
#       js: "() => window.loadingComplete === true"  # REQUIRED for type: js
#
#   extraction:
#     type: "css"
#     base_selector: ".property-card"
#     fields:
#       - name: "title"
#         selector: ".title"
#         type: "text"
#       - name: "price_text"
#         selector: ".price"
#         type: "text"
#
#   output:
#     required_fields:
#       - "title"
#     unique_key:
#       - "title"
#     files:
#       csv: "results.csv"
#       json: "results.json"
#     transform: []

# =============================================================================
# CONFIGURATION REFERENCE
# =============================================================================
#
# PAGINATION TYPES:
# -----------------
# type: "url"   - Traditional URL-based pagination
#                 Loop: extract page 1 → next URL → extract page 2 → ...
#                 Config: start_page, max_pages, page_template
#
# type: "js"    - JavaScript-based pagination (load more buttons, infinite scroll)
#                 Runs JS once to load all content, then extracts once
#                 Config: js_code, wait_for (REQUIRED)
#
# type: "none"  - Single page, no pagination (default)
#
# WAIT_FOR OPTIONS:
# -----------------
# wait_for:
#   css: ".selector"           # Wait for CSS selector to appear
#   js: "() => expression"     # Wait for JS expression to return true
#   time: 5000                 # Wait fixed milliseconds
#
# EXTRACTION TYPES:
# -----------------
# type: "css"   - CSS selector-based extraction
#                 Requires: base_selector, fields
#
# type: "llm"   - LLM-based extraction (uses AI to extract data)
#                 Requires: provider, instruction
#                 Optional: images (for vision analysis)
#
# INTERACTIONS:
# -------------
# Pre-extraction actions to prepare the page:
#   - type: "click"
#     selector: ".button"
#     wait_after_ms: 1000
#
#   - type: "js"
#     code: "custom javascript code"
#     wait_after_ms: 500
